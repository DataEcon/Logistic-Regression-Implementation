{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as m\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.utils import shuffle\n",
    "#from ggplot import *\n",
    "#from pandas.lib import Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= \"C:/Users/psais/OneDrive/Desktop/sowmya/Subjects Sem 2/DataSets/Datasets for Predictive Modelling with Python-20190708T233651Z-001/Datasets for Predictive Modelling with Python/Chapter 2/titanic3.csv\" \n",
    "df= pd.read_csv(file,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering only the numerical variables\n",
    "drop_Var = ['cabin','home.dest','embarked']\n",
    "df= df.drop(drop_Var,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sex=pd.get_dummies(df['sex'])\n",
    "df=pd.concat([df,df_sex],axis=1)\n",
    "df.drop(columns=['sex','name','body','boat','ticket'],inplace=True)\n",
    "#Handling m missing values\n",
    "df['age'].isnull().sum()\n",
    "df['age']=df['age'].fillna(df['age'].median())\n",
    "df['age'].isnull().sum()\n",
    "df= shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pclass']=df['pclass'].fillna(df['pclass'].median())\n",
    "df['fare']=df['fare'].fillna(df['fare'].mean())\n",
    "df['sibsp']=df['sibsp'].fillna(df['sibsp'].median())\n",
    "df['parch']=df['parch'].fillna(df['parch'].median())\n",
    "df['survived']=df['survived'].fillna(df['survived'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df.drop(columns=\"survived\")\n",
    "y= df['survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,testX,trainY,testY = train_test_split(x,y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass    0\n",
       "age       0\n",
       "sibsp     0\n",
       "parch     0\n",
       "fare      0\n",
       "female    0\n",
       "male      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.isnull().sum()\n",
    "trainX.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(trainY,trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.466083\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "params=model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>survived</td>     <th>  No. Observations:  </th>  <td>  1048</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  1041</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 19 Aug 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.3041</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>15:03:29</td>     <th>  Log-Likelihood:    </th> <td> -488.45</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -701.86</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>4.805e-89</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pclass</th> <td>   -1.0497</td> <td>    0.130</td> <td>   -8.048</td> <td> 0.000</td> <td>   -1.305</td> <td>   -0.794</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>    <td>   -0.0402</td> <td>    0.007</td> <td>   -5.665</td> <td> 0.000</td> <td>   -0.054</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sibsp</th>  <td>   -0.3213</td> <td>    0.097</td> <td>   -3.322</td> <td> 0.001</td> <td>   -0.511</td> <td>   -0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>parch</th>  <td>   -0.0675</td> <td>    0.095</td> <td>   -0.710</td> <td> 0.478</td> <td>   -0.254</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fare</th>   <td>    0.0027</td> <td>    0.002</td> <td>    1.168</td> <td> 0.243</td> <td>   -0.002</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th> <td>    4.7106</td> <td>    0.486</td> <td>    9.695</td> <td> 0.000</td> <td>    3.758</td> <td>    5.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>male</th>   <td>    2.1756</td> <td>    0.443</td> <td>    4.910</td> <td> 0.000</td> <td>    1.307</td> <td>    3.044</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               survived   No. Observations:                 1048\n",
       "Model:                          Logit   Df Residuals:                     1041\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Mon, 19 Aug 2019   Pseudo R-squ.:                  0.3041\n",
       "Time:                        15:03:29   Log-Likelihood:                -488.45\n",
       "converged:                       True   LL-Null:                       -701.86\n",
       "                                        LLR p-value:                 4.805e-89\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "pclass        -1.0497      0.130     -8.048      0.000      -1.305      -0.794\n",
       "age           -0.0402      0.007     -5.665      0.000      -0.054      -0.026\n",
       "sibsp         -0.3213      0.097     -3.322      0.001      -0.511      -0.132\n",
       "parch         -0.0675      0.095     -0.710      0.478      -0.254       0.119\n",
       "fare           0.0027      0.002      1.168      0.243      -0.002       0.007\n",
       "female         4.7106      0.486      9.695      0.000       3.758       5.663\n",
       "male           2.1756      0.443      4.910      0.000       1.307       3.044\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False False False  True  True]\n",
      "[1 3 2 4 5 1 1]\n"
     ]
    }
   ],
   "source": [
    "# looking at the pvalues, p value<0.05 make significant predicator. Hence feature selection is a best option here\n",
    "model1 = LogisticRegression()\n",
    "rfe = RFE(model1,3)\n",
    "rfe = rfe.fit(trainX,trainY )\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pclass', 'age', 'sibsp', 'parch', 'fare', 'female', 'male'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_col= ['pclass','sibsp','male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX=trainX[select_col]\n",
    "testX=testX[select_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.566768\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               survived   No. Observations:                 1048\n",
      "Model:                          Logit   Df Residuals:                     1045\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Mon, 19 Aug 2019   Pseudo R-squ.:                  0.1537\n",
      "Time:                        15:03:32   Log-Likelihood:                -593.97\n",
      "converged:                       True   LL-Null:                       -701.86\n",
      "                                        LLR p-value:                 1.401e-47\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "pclass         0.1358      0.046      2.972      0.003       0.046       0.225\n",
      "sibsp         -0.0353      0.068     -0.522      0.602      -0.168       0.097\n",
      "male          -1.6998      0.142    -11.989      0.000      -1.978      -1.422\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# rerunning model with the selected variables\n",
    "logit_model=sm.Logit(trainY,trainX)\n",
    "result=logit_model.fit()\n",
    "print (result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction using sklearn \n",
    "clf= LogisticRegression()\n",
    "clf.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7843511450381679"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our accuracy came out to be 80% with 3 variables and R**2 values as 19. \n",
    "# checking for mean square error\n",
    "predicted=clf.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816793893129771\n"
     ]
    }
   ],
   "source": [
    "print (m.accuracy_score(testY, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us retry using all the variables\n",
    "trainX,testX,trainY,testY = train_test_split(x,y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted1= clf1.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7938931297709924\n"
     ]
    }
   ],
   "source": [
    "print (m.accuracy_score(testY, predicted1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7891221374045801"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.score(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using all the features is more productive here. R**2 came out to be 31%,  score on train set is 78%, accuracy on test set is 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80606061 0.78787879 0.80487805 0.75609756 0.7607362  0.80981595\n",
      " 0.77300613 0.78527607]\n",
      "0.785468669940464\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation using sklearn \n",
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(LogisticRegression(),x, y,scoring='accuracy', cv=8)\n",
    "print (scores)\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the average accuracy is 78.7% which is close to the accurcy we achieved on the clf1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[139,  23],\n",
       "       [ 31,  69]], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion Matrix\n",
    "m.confusion_matrix(testY, predicted1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>139</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>31</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0.0  1.0\n",
       "survived          \n",
       "0.0       139   23\n",
       "1.0        31   69"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way to get the confusion matrix\n",
    "pd.crosstab(testY,predicted1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3877551020408163\n",
      "0.7012195121951219\n"
     ]
    }
   ],
   "source": [
    "#Sensitivity and specificity\n",
    "sens= 38/(60+38)\n",
    "specif =1-( 49/(115+49))\n",
    "print(sens)\n",
    "print(specif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for varying threshold , find sensitivity and specificity and check the accuracy\n",
    "prob = clf1.predict_proba(testX)[:,1]\n",
    "fpr, sensitivity, _ = m.roc_curve(testY, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ggplot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-d9ab152d136c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# creating a dataframe to store false positive results and sensitivity value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mggplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fpr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sensitivity'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mgeom_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mgeom_abline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinetype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dashed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ggplot' is not defined"
     ]
    }
   ],
   "source": [
    "# creating a dataframe to store false positive results and sensitivity value\n",
    "df = pd.DataFrame(dict(fpr=fpr, sensitivity=sensitivity))\n",
    "ggplot(df, aes(x='fpr', y='sensitivity')) +\\\n",
    "geom_line() +\\\n",
    "geom_abline(linetype='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-8a0306c1d7b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# AUC curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#auc = metrics.auc(fpr,sensitivity)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    275\u001b[0m     return _average_binary_score(\n\u001b[0;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: continuous format is not supported"
     ]
    }
   ],
   "source": [
    "# AUC curve\n",
    "#auc = metrics.auc(fpr,sensitivity)\n",
    "auc = roc_auc_score(fpr,sensitivity)\n",
    "fpr, tpr, thresholds = roc_curve(fpr,sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve and Accuracy plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
